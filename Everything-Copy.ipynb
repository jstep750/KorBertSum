{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fe3e6d-c2ad-488f-8189-54ccf427e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Bertsum directory chdir\n",
    "os.chdir('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23bdeb51-9e51-4f96-bf75-8aafbca39953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/    \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mprepro\u001b[0m/        requirements.txt  train.py\n",
      "distributed.py  \u001b[01;34mothers\u001b[0m/  preprocess.py  \u001b[01;34mtmp\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36681447-acbb-41bc-b59a-622ec4016310",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 추출요약 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09dbd66f-a905-48b6-8023-32c59534186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Main training workflow\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "\n",
    "import distributed\n",
    "from models import data_loader, model_builder\n",
    "from models.data_loader import load_dataset\n",
    "from models.model_builder import Summarizer\n",
    "from tensorboardX import SummaryWriter\n",
    "from models.reporter import ReportMgr\n",
    "from models.stats import Statistics\n",
    "from others.logging import logger\n",
    "# from models.trainer import build_trainer\n",
    "# build_trainer의 dependency package pyrouge.utils가 import되지 않아 직접 셀에 삽입\n",
    "from others.logging import logger, init_logger\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"encoder\":'classifier',\n",
    "    \"mode\":'summary',\n",
    "    \"bert_data_path\":'../bert_sample/korean',\n",
    "    \"model_path\":'../models/bert_classifier',\n",
    "    \"bert_model\":'../001_bert_morp_pytorch',\n",
    "    \"result_path\":'../results/korean',\n",
    "    \"temp_dir\":'.',\n",
    "    \"bert_config_path\":'../001_bert_morp_pytorch/bert_config.json',\n",
    "    \"batch_size\":1000,\n",
    "    \"use_interval\":True,\n",
    "    \"hidden_size\":128,\n",
    "    \"ff_size\":512,\n",
    "    \"heads\":4,\n",
    "    \"inter_layers\":2,\n",
    "    \"rnn_size\":512,\n",
    "    \"param_init\":0,\n",
    "    \"param_init_glorot\":True,\n",
    "    \"dropout\":0.1,\n",
    "    \"optim\":'adam',\n",
    "    \"lr\":2e-3,\n",
    "    \"report_every\":1,\n",
    "    \"save_checkpoint_steps\":5,\n",
    "    \"block_trigram\":True,\n",
    "    \"recall_eval\":False,\n",
    "    \n",
    "    \"accum_count\":1,\n",
    "    \"world_size\":1,\n",
    "    \"visible_gpus\":'-1',\n",
    "    \"gpu_ranks\":'0',\n",
    "    \"log_file\":'../logs/bert_classifier',\n",
    "    \"test_from\":'../models/bert_classifier2/model_step_35000.pt'\n",
    "})\n",
    "\n",
    "\n",
    "def build_trainer(args, device_id, model,\n",
    "                  optim):\n",
    "    \"\"\"\n",
    "    Simplify `Trainer` creation based on user `opt`s*\n",
    "    Args:\n",
    "        opt (:obj:`Namespace`): user options (usually from argument parsing)\n",
    "        model (:obj:`onmt.models.NMTModel`): the model to train\n",
    "        fields (dict): dict of fields\n",
    "        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n",
    "        data_type (str): string describing the type of data\n",
    "            e.g. \"text\", \"img\", \"audio\"\n",
    "        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n",
    "            used to save the model\n",
    "    \"\"\"\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "\n",
    "\n",
    "    grad_accum_count = args.accum_count\n",
    "    n_gpu = args.world_size\n",
    "\n",
    "    if device_id >= 0:\n",
    "        gpu_rank = int(args.gpu_ranks[device_id])\n",
    "    else:\n",
    "        gpu_rank = 0\n",
    "        n_gpu = 0\n",
    "\n",
    "    #print('gpu_rank %d' % gpu_rank)\n",
    "\n",
    "    tensorboard_log_dir = args.model_path\n",
    "\n",
    "    writer = SummaryWriter(tensorboard_log_dir, comment=\"Unmt\")\n",
    "\n",
    "    report_manager = ReportMgr(args.report_every, start_time=-1, tensorboard_writer=writer)\n",
    "\n",
    "    trainer = Trainer(args, model, optim, grad_accum_count, n_gpu, gpu_rank, report_manager)\n",
    "\n",
    "    # print(tr)\n",
    "    if (model):\n",
    "        n_params = _tally_parameters(model)\n",
    "        #logger.info('* number of parameters: %d' % n_params)\n",
    "\n",
    "    return trainer\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Class that controls the training process.\n",
    "\n",
    "    Args:\n",
    "            model(:py:class:`onmt.models.model.NMTModel`): translation model\n",
    "                to train\n",
    "            train_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            valid_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            optim(:obj:`onmt.utils.optimizers.Optimizer`):\n",
    "               the optimizer responsible for update\n",
    "            trunc_size(int): length of truncated back propagation through time\n",
    "            shard_size(int): compute loss in shards of this size for efficiency\n",
    "            data_type(string): type of the source input: [text|img|audio]\n",
    "            norm_method(string): normalization methods: [sents|tokens]\n",
    "            grad_accum_count(int): accumulate gradients this many times.\n",
    "            report_manager(:obj:`onmt.utils.ReportMgrBase`):\n",
    "                the object that creates reports, or None\n",
    "            model_saver(:obj:`onmt.models.ModelSaverBase`): the saver is\n",
    "                used to save a checkpoint.\n",
    "                Thus nothing will be saved if this parameter is None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  args, model,  optim,\n",
    "                  grad_accum_count=1, n_gpu=1, gpu_rank=1,\n",
    "                  report_manager=None):\n",
    "        # Basic attributes.\n",
    "        self.args = args\n",
    "        self.save_checkpoint_steps = args.save_checkpoint_steps\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.grad_accum_count = grad_accum_count\n",
    "        self.n_gpu = n_gpu\n",
    "        self.gpu_rank = gpu_rank\n",
    "        self.report_manager = report_manager\n",
    "\n",
    "        self.loss = torch.nn.BCELoss(reduction='none')\n",
    "        assert grad_accum_count > 0\n",
    "        # Set model in training mode.\n",
    "        if (model):\n",
    "            self.model.train()\n",
    "\n",
    "    def summary(self, test_iter, step, cal_lead=False, cal_oracle=False):\n",
    "        \"\"\" Validate model.\n",
    "            valid_iter: validate data iterator\n",
    "        Returns:\n",
    "            :obj:`nmt.Statistics`: validation loss statistics\n",
    "        \"\"\"\n",
    "        # Set model in validating mode.\n",
    "        def _get_ngrams(n, text):\n",
    "            ngram_set = set()\n",
    "            text_length = len(text)\n",
    "            max_index_ngram_start = text_length - n\n",
    "            for i in range(max_index_ngram_start + 1):\n",
    "                ngram_set.add(tuple(text[i:i + n]))\n",
    "            return ngram_set\n",
    "\n",
    "        def _block_tri(c, p):\n",
    "            tri_c = _get_ngrams(3, c.split())\n",
    "            for s in p:\n",
    "                tri_s = _get_ngrams(3, s.split())\n",
    "                if len(tri_c.intersection(tri_s))>0:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        if (not cal_lead and not cal_oracle):\n",
    "            self.model.eval()\n",
    "        stats = Statistics()\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_iter:\n",
    "                src = batch.src\n",
    "                labels = batch.labels\n",
    "                segs = batch.segs\n",
    "                clss = batch.clss\n",
    "                mask = batch.mask\n",
    "                mask_cls = batch.mask_cls\n",
    "\n",
    "\n",
    "                gold = []\n",
    "                pred = []\n",
    "\n",
    "                if (cal_lead):\n",
    "                    selected_ids = [list(range(batch.clss.size(1)))] * batch.batch_size\n",
    "                elif (cal_oracle):\n",
    "                    selected_ids = [[j for j in range(batch.clss.size(1)) if labels[i][j] == 1] for i in\n",
    "                                    range(batch.batch_size)]\n",
    "                else:\n",
    "                    sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "\n",
    "                    # loss = self.loss(sent_scores, labels.float())\n",
    "                    # loss = (loss * mask.float()).sum()\n",
    "                    # batch_stats = Statistics(float(loss.cpu().data.numpy()), len(labels))\n",
    "                    # stats.update(batch_stats)\n",
    "\n",
    "                    sent_scores = sent_scores + mask.float()\n",
    "                    sent_scores = sent_scores.cpu().data.numpy()\n",
    "                    selected_ids = np.argsort(-sent_scores, 1)\n",
    "                # selected_ids = np.sort(selected_ids,1)\n",
    "                \n",
    "\n",
    "        return selected_ids\n",
    "\n",
    "\n",
    "    def _gradient_accumulation(self, true_batchs, normalization, total_stats,\n",
    "                               report_stats):\n",
    "        if self.grad_accum_count > 1:\n",
    "            self.model.zero_grad()\n",
    "\n",
    "        for batch in true_batchs:\n",
    "            if self.grad_accum_count == 1:\n",
    "                self.model.zero_grad()\n",
    "\n",
    "            src = batch.src\n",
    "            labels = batch.labels\n",
    "            segs = batch.segs\n",
    "            clss = batch.clss\n",
    "            mask = batch.mask\n",
    "            mask_cls = batch.mask_cls\n",
    "\n",
    "            sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "\n",
    "            loss = self.loss(sent_scores, labels.float())\n",
    "            loss = (loss*mask.float()).sum()\n",
    "            (loss/loss.numel()).backward()\n",
    "            # loss.div(float(normalization)).backward()\n",
    "\n",
    "            batch_stats = Statistics(float(loss.cpu().data.numpy()), normalization)\n",
    "\n",
    "\n",
    "            total_stats.update(batch_stats)\n",
    "            report_stats.update(batch_stats)\n",
    "\n",
    "            # 4. Update the parameters and statistics.\n",
    "            if self.grad_accum_count == 1:\n",
    "                # Multi GPU gradient gather\n",
    "                if self.n_gpu > 1:\n",
    "                    grads = [p.grad.data for p in self.model.parameters()\n",
    "                             if p.requires_grad\n",
    "                             and p.grad is not None]\n",
    "                    distributed.all_reduce_and_rescale_tensors(\n",
    "                        grads, float(1))\n",
    "                self.optim.step()\n",
    "\n",
    "        # in case of multi step gradient accumulation,\n",
    "        # update only after accum batches\n",
    "        if self.grad_accum_count > 1:\n",
    "            if self.n_gpu > 1:\n",
    "                grads = [p.grad.data for p in self.model.parameters()\n",
    "                         if p.requires_grad\n",
    "                         and p.grad is not None]\n",
    "                distributed.all_reduce_and_rescale_tensors(\n",
    "                    grads, float(1))\n",
    "            self.optim.step()\n",
    "\n",
    "    def _save(self, step):\n",
    "        real_model = self.model\n",
    "        # real_generator = (self.generator.module\n",
    "        #                   if isinstance(self.generator, torch.nn.DataParallel)\n",
    "        #                   else self.generator)\n",
    "\n",
    "        model_state_dict = real_model.state_dict()\n",
    "        # generator_state_dict = real_generator.state_dict()\n",
    "        checkpoint = {\n",
    "            'model': model_state_dict,\n",
    "            # 'generator': generator_state_dict,\n",
    "            'opt': self.args,\n",
    "            'optim': self.optim,\n",
    "        }\n",
    "        checkpoint_path = os.path.join(self.args.model_path, 'model_step_%d.pt' % step)\n",
    "        #logger.info(\"Saving checkpoint %s\" % checkpoint_path)\n",
    "        # checkpoint_path = '%s_step_%d.pt' % (FLAGS.model_path, step)\n",
    "        if (not os.path.exists(checkpoint_path)):\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            return checkpoint, checkpoint_path\n",
    "\n",
    "    def _start_report_manager(self, start_time=None):\n",
    "        \"\"\"\n",
    "        Simple function to start report manager (if any)\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            if start_time is None:\n",
    "                self.report_manager.start()\n",
    "            else:\n",
    "                self.report_manager.start_time = start_time\n",
    "\n",
    "    def _maybe_gather_stats(self, stat):\n",
    "        \"\"\"\n",
    "        Gather statistics in multi-processes cases\n",
    "\n",
    "        Args:\n",
    "            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n",
    "                or None (it returns None in this case)\n",
    "\n",
    "        Returns:\n",
    "            stat: the updated (or unchanged) stat object\n",
    "        \"\"\"\n",
    "        if stat is not None and self.n_gpu > 1:\n",
    "            return Statistics.all_gather_stats(stat)\n",
    "        return stat\n",
    "\n",
    "    def _maybe_report_training(self, step, num_steps, learning_rate,\n",
    "                               report_stats):\n",
    "        \"\"\"\n",
    "        Simple function to report training stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_training` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_training(\n",
    "                step, num_steps, learning_rate, report_stats,\n",
    "                multigpu=self.n_gpu > 1)\n",
    "\n",
    "    def _report_step(self, learning_rate, step, train_stats=None,\n",
    "                     valid_stats=None):\n",
    "        \"\"\"\n",
    "        Simple function to report stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_step` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_step(\n",
    "                learning_rate, step, train_stats=train_stats,\n",
    "                valid_stats=valid_stats)\n",
    "\n",
    "    def _maybe_save(self, step):\n",
    "        \"\"\"\n",
    "        Save the model if a model saver is set\n",
    "        \"\"\"\n",
    "        if self.model_saver is not None:\n",
    "            self.model_saver.maybe_save(step)\n",
    "\n",
    "            \n",
    "def summary(args, b_list, device_id, pt, step, model):\n",
    "\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "    if (pt != ''):\n",
    "        test_from = pt\n",
    "    else:\n",
    "        test_from = args.test_from\n",
    "    \n",
    "    opt = vars(checkpoint['opt'])\n",
    "    for k in opt.keys():\n",
    "        if (k in model_flags):\n",
    "            setattr(args, k, opt[k])\n",
    "    #print(args)\n",
    "\n",
    "    model.load_cp(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    test_iter =data_loader.Dataloader(args, _lazy_dataset_loader(b_list),\n",
    "                                  args.batch_size, device,\n",
    "                                  shuffle=False, is_test=True)\n",
    "    trainer = build_trainer(args, device_id, model, None)\n",
    "    result = trainer.summary(test_iter,step)\n",
    "    return result\n",
    "\n",
    "def _tally_parameters(model):\n",
    "    n_params = sum([p.nelement() for p in model.parameters()])\n",
    "    return n_params\n",
    "\n",
    "args.gpu_ranks = [int(i) for i in args.gpu_ranks.split(',')]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.visible_gpus\n",
    "\n",
    "init_logger(args.log_file)\n",
    "device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "device_id = 0 if device == \"cuda\" else -1\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers','encoder','ff_actv', 'use_interval','rnn_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3622ff59-a47f-4b5c-b236-57e73c5ca3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 08:22:32.782757: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-19 08:22:32.782796: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import urllib3\n",
    "from glob import glob\n",
    "import collections\n",
    "import six\n",
    "import gc\n",
    "import gluonnlp as nlp\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.utils import download as _download\n",
    "\n",
    "def do_lang ( openapi_key, text ) :\n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    requestJson = {  \n",
    "        \"argument\": {\n",
    "            \"text\": text,\n",
    "            \"analysis_code\": \"morp\"\n",
    "        }\n",
    "    }\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request(\n",
    "        \"POST\",\n",
    "        openApiURL,\n",
    "        headers={\"Content-Type\": \"application/json; charset=UTF-8\", \"Authorization\" :  openapi_key},\n",
    "        body=json.dumps(requestJson)\n",
    "    )\n",
    "\n",
    "    json_data = json.loads(response.data.decode('utf-8'))\n",
    "    json_result = json_data[\"result\"]\n",
    "    \n",
    "    if json_result == -1:\n",
    "        json_reason = json_data[\"reason\"]\n",
    "        if \"Invalid Access Key\" in json_reason:\n",
    "            logger.info(json_reason)\n",
    "            logger.info(\"Please check the openapi access key.\")\n",
    "            sys.exit()\n",
    "        return \"openapi error - \" + json_reason\n",
    "    else:\n",
    "        json_data = json.loads(response.data.decode('utf-8'))\n",
    "    \n",
    "        json_return_obj = json_data[\"return_object\"]\n",
    "        \n",
    "        return_result = \"\"\n",
    "        json_sentence = json_return_obj[\"sentence\"]\n",
    "        for json_morp in json_sentence:\n",
    "            for morp in json_morp[\"morp\"]:\n",
    "                return_result = return_result+str(morp[\"lemma\"])+\"/\"+str(morp[\"type\"])+\" \"\n",
    "\n",
    "        return return_result\n",
    "\n",
    "def get_kobert_vocab(cachedir=\"./tmp/\"):\n",
    "    # Add BOS,EOS vocab\n",
    "    tokenizer = {\n",
    "        \"url\": \"s3://skt-lsl-nlp-model/KoBERT/tokenizers/kobert_news_wiki_ko_cased-1087f8699e.spiece\",\n",
    "        #\"fname\": \"/opt/ml/SumAI/bertsum/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\",\n",
    "        \"chksum\": \"ae5711deb3\",\n",
    "    }\n",
    "    \n",
    "    vocab_info = tokenizer\n",
    "    vocab_file = _download(\n",
    "        #vocab_info[\"url\"], vocab_info[\"fname\"], vocab_info[\"chksum\"], cachedir=cachedir\n",
    "        vocab_info[\"url\"], vocab_info[\"chksum\"], cachedir=cachedir\n",
    "    )\n",
    "\n",
    "    vocab_b_obj = nlp.vocab.BERTVocab.from_sentencepiece(\n",
    "        vocab_file[0], padding_token=\"[PAD]\", bos_token=\"[BOS]\", eos_token=\"[EOS]\"\n",
    "    )\n",
    "    return vocab_b_obj\n",
    "\n",
    "    \n",
    "class BertData():\n",
    "    def __init__(self, vocab):\n",
    "        self.tokenizer = nlp.data.BERTSPTokenizer(get_tokenizer(), vocab, lower=False)\n",
    "        #self.tokenizer = Tokenizer(vocab_file_path)\n",
    "        self.sep_vid = self.tokenizer.vocab['[SEP]']\n",
    "        self.cls_vid = self.tokenizer.vocab['[CLS]']\n",
    "        self.pad_vid = self.tokenizer.vocab['[PAD]']\n",
    "\n",
    "    def preprocess(self, src):\n",
    "\n",
    "        if (len(src) == 0):\n",
    "            return None\n",
    "\n",
    "        original_src_txt = [''.join(s) for s in src]\n",
    "\n",
    "\n",
    "        idxs = [i for i, s in enumerate(src) if (len(s) > 0)]\n",
    "\n",
    "        src = [src[i][:20000] for i in idxs]\n",
    "        src = src[:10000]\n",
    "\n",
    "        if (len(src) < 3):\n",
    "            return None\n",
    "\n",
    "        src_txt = [''.join(sent) for sent in src]\n",
    "        text = ' [SEP] [CLS] '.join(src_txt)\n",
    "        src_subtokens = text.split(' ')\n",
    "        src_subtokens = src_subtokens[:510]\n",
    "        src_subtokens = ['[CLS]'] + src_subtokens + ['[SEP]']\n",
    "\n",
    "        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n",
    "        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n",
    "        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
    "        segments_ids = []\n",
    "        for i, s in enumerate(segs):\n",
    "            if (i % 2 == 0):\n",
    "                segments_ids += s * [0]\n",
    "            else:\n",
    "                segments_ids += s * [1]\n",
    "        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n",
    "        labels = None\n",
    "        tgt_txt = None\n",
    "        src_txt = [original_src_txt[i] for i in idxs]\n",
    "        return src_subtoken_idxs, labels, segments_ids, cls_ids, src_txt, tgt_txt\n",
    "    \n",
    "def convert_to_unicode(text):\n",
    "    \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        elif isinstance(text, unicode):\n",
    "            return text\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")\n",
    "        \n",
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self, vocab_file_path):\n",
    "        self.vocab_file_path = vocab_file_path\n",
    "        \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "        vocab = collections.OrderedDict()\n",
    "        index = 0\n",
    "        with open(self.vocab_file_path, \"r\", encoding='utf-8') as reader:\n",
    "\n",
    "            while True:\n",
    "                token = convert_to_unicode(reader.readline())\n",
    "                if not token:\n",
    "                    break\n",
    "\n",
    "          ### joonho.lim @ 2019-03-15\n",
    "                if token.find('n_iters=') == 0 or token.find('max_length=') == 0 :\n",
    "\n",
    "                    continue\n",
    "                token = token.split('\\t')[0].strip('_')\n",
    "\n",
    "                token = token.strip()\n",
    "                vocab[token] = index\n",
    "                index += 1\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        \"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"\n",
    "        ids = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                ids.append(self.vocab[token])\n",
    "            except:\n",
    "                ids.append(1)\n",
    "        if len(ids) > 10000:\n",
    "            raise ValueError(\n",
    "                \"Token indices sequence length is longer than the specified maximum \"\n",
    "                \" sequence length for this BERT model ({} > {}). Running this\"\n",
    "                \" sequence through BERT will result in indexing errors\".format(len(ids), 10000)\n",
    "            )\n",
    "        return ids\n",
    "\n",
    "\n",
    "def _lazy_dataset_loader(pt_file):\n",
    "    dataset = pt_file    \n",
    "    yield dataset\n",
    "    \n",
    "def News_to_input(text, openapi_key):\n",
    "    newstemp = do_lang(openapi_key, text)\n",
    "    news = newstemp.split(' ./SF ')[:-1]\n",
    "    vocab = get_kobert_vocab()\n",
    "    tokenizer = nlp.data.BERTSPTokenizer(get_tokenizer(), vocab, lower=False)\n",
    "    bertdata = BertData(vocab)\n",
    "    sent_labels = [0] * len(news)\n",
    "    tmp = bertdata.preprocess(news)\n",
    "    if(not tmp): return None\n",
    "    #print(tmp)\n",
    "    b_data_dict = {\"src\":tmp[0],\n",
    "               \"tgt\": [0],\n",
    "               \"labels\":[0,0,0],\n",
    "               \"src_sent_labels\":sent_labels,\n",
    "               \"segs\":tmp[2],\n",
    "               \"clss\":tmp[3],\n",
    "               \"src_txt\":tmp[4],\n",
    "               \"tgt_txt\":'hehe'}\n",
    "    b_list = []\n",
    "    b_list.append(b_data_dict) \n",
    "    return b_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3381c-d48f-4c1a-ab2f-5783a2a3344b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 추출요약 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739aa86a-055a-4b7f-85b6-dfbf660c2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-19 14:39:27,221 INFO] loading archive file ../001_bert_morp_pytorch\n",
      "[2023-01-19 14:39:27,223 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 7 3 1 4 5 2 6]]\n",
      "------------------------------------------------------------\n",
      "[0, 7, 3]\n",
      "------------------------------------------------------------\n",
      "0 \n",
      "일본 정부가 문재인 대통령이 도쿄올림픽을 계기로 일본을 방문하는 방향으로 한일 양국이 조율하고 있다는 15일 요미우리신문의 보도를 부인했다\n",
      "3 \n",
      "한국 측은 문 대통령의 방일 때 스가 요시히데(菅義偉) 총리와 처음으로 정상회담을 하겠다는 생각이라고 요미우리는 전했다\n",
      "7 \n",
      "그러면서 “다케시마 문제에 대해서는 계속 우리나라의 영토, 영해, 영공을 단호히 지키겠다는 결의로 냉정하고 의연하게 대응해갈 생각”이라고 밝혔다\n",
      "------------------------------------------------------------\n",
      "\n",
      "일본 정부가 문재인 대통령이 도쿄올림픽을 계기로 일본을 방문하는 방향으로 한일 양국이 조율하고 있다는 15일 요미우리신문의 보도를 부인했다. \n",
      "한국 측은 문 대통령의 방일 때 스가 요시히데(菅義偉) 총리와 처음으로 정상회담을 하겠다는 생각이라고 요미우리는 전했다. \n",
      "그러면서 “다케시마 문제에 대해서는 계속 우리나라의 영토, 영해, 영공을 단호히 지키겠다는 결의로 냉정하고 의연하게 대응해갈 생각”이라고 밝혔다. \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "openapi_key = '9318dc23-24ac-4b59-a99e-a29ec170bf02'\n",
    "chat_history = \"뉴스 \"\n",
    "user_input = '''\n",
    "일본 정부가 문재인 대통령이 도쿄올림픽을 계기로 일본을 방문하는 방향으로 한일 양국이 조율하고 있다는 15일 요미우리신문의 보도를 부인했다.\n",
    "정부 대변인인 가토 가쓰노부(加藤勝信) 관방장관은 이날 오전 정례 기자회견에서 관련 질문에 “말씀하신 보도와 같은 사실이 없는 것으로 안다”고 밝혔다.\n",
    "앞서 요미우리는 한국 측이 도쿄올림픽을 계기로 한 문 대통령의 방일을 타진했고, 일본 측은 수용하는 방향이라고 이날 보도했다.\n",
    "한국 측은 문 대통령의 방일 때 스가 요시히데(菅義偉) 총리와 처음으로 정상회담을 하겠다는 생각이라고 요미우리는 전했다.\n",
    "가토 장관은 한일 정상회담에 대한 일본 정부의 자세에 대해 “그런 사실이 없기 때문에 가정의 질문에 대해 답하는 것을 삼가겠다”고 말했다.\n",
    "그는 한국 측의 독도방어훈련에 ‘어떤 대항 조치를 생각하고 있느냐’는 질문에는 “한국 해군의 훈련에 대해 정부로서는 강한 관심을 가지고 주시하는 상황이어서 지금 시점에선 논평을 삼가겠다”고 말을 아꼈다.\n",
    "가토 장관은 “다케시마(竹島·일본이 주장하는 독도의 명칭)는 역사적 사실에 비춰봐도, 국제법상으로도 명백한 일본 고유의 영토”라며 독도 영유권 주장을 되풀이했다.\n",
    "그러면서 “다케시마 문제에 대해서는 계속 우리나라의 영토, 영해, 영공을 단호히 지키겠다는 결의로 냉정하고 의연하게 대응해갈 생각”이라고 밝혔다.\n",
    "'''\n",
    "\n",
    "\n",
    "bot_input_ids = News_to_input(chat_history + user_input, openapi_key)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "#logger.info('Loading checkpoint from %s' % test_from)\n",
    "checkpoint = torch.load('../models/bert_classifier/model_step_1000.pt', map_location=lambda storage, loc: storage)\n",
    "config = BertConfig.from_json_file(args.bert_config_path)\n",
    "model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "    \n",
    "chat_history_ids = summary(args, bot_input_ids, -1, '', None, model)\n",
    "print(chat_history_ids)\n",
    "print('------------------------------------------------------------')\n",
    "pred_lst = list(chat_history_ids[0][:3])\n",
    "print(pred_lst)\n",
    "print('------------------------------------------------------------')\n",
    "final_text = ''\n",
    "for i,a in enumerate(user_input.split('.')):\n",
    "    if i in pred_lst:\n",
    "        print(i, a)\n",
    "        final_text = final_text+a+'. '\n",
    "chat_history = user_input + '<token>' +final_text\n",
    "print('------------------------------------------------------------')\n",
    "print(final_text)\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beaba62c-2ff1-47eb-be8d-e3716479cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-19 08:23:05,635 INFO] loading archive file ../001_bert_morp_pytorch\n",
      "[2023-01-19 08:23:05,637 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('../models/bert_classifier2/model_step_35000.pt', map_location=lambda storage, loc: storage)\n",
    "config = BertConfig.from_json_file(args.bert_config_path)\n",
    "model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "    \n",
    "def get_topk_sentences(k, user_input, model):\n",
    "    bot_input_ids = News_to_input(user_input, openapi_key)\n",
    "    \n",
    "    chat_history_ids = summary(args, bot_input_ids, -1, '', None, model)\n",
    "    pred_lst = list(chat_history_ids[0][:k])\n",
    "    final_text = []\n",
    "    for i,a in enumerate(user_input.split('.')):\n",
    "        if i in pred_lst:\n",
    "            #print(i, a)\n",
    "            final_text.append((i, a+'. '))\n",
    "    #print('------------------------------------------------------------')\n",
    "    return final_text\n",
    "    \n",
    "    \n",
    "#print(get_topk_sentences(4, user_input, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dc4119-7c54-4164-97b5-005c459fcaf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c3976-e9f5-4c29-94a7-b24450fb1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_df = pd.read_csv('../result(paraphrase).csv')\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e335c-53b7-4bda-82aa-287589401677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "def context(x):\n",
    "    try:\n",
    "        article = Article(x, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef9280-f0b1-4818-9171-14ca267bca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7db07-a218-471d-9ec6-beca8ec8206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for i in sorted(all_df['Topic'].unique()):\n",
    "    if(i != -1):\n",
    "        print(i, len(all_df[all_df['Topic'] == i]))\n",
    "        topics.append(all_df[all_df['Topic'] == i])\n",
    "    \n",
    "topics[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f8f37-90af-48cc-ae33-c10e368b6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = topics[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888445a-e27e-4097-8bf9-a7b164a01589",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906eb3b3-df3a-4a04-ad30-b24d9de9d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "contexts = []\n",
    "delete_idx = []\n",
    "for i, link in enumerate(tqdm(topic_df['link'])):\n",
    "    cont = context(link)\n",
    "    if(context):\n",
    "        contexts.append(cont)\n",
    "    else:\n",
    "        print(context)\n",
    "        delete_idx.append(i)\n",
    "        \n",
    "    \n",
    "print(len(delete_idx), delete_idx)\n",
    "print(len(topic_df))\n",
    "topic_df = topic_df.drop(topic_df.index[delete_idx])\n",
    "print(len(topic_df))\n",
    "topic_df['context'] = contexts\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f53d12-091d-4c5a-95fc-68c064f312c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in topic_df['title']:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "29f105fa-1d22-4d1b-ac69-4a6146800ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.to_csv('../paraphrase_topic15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a7913ee7-ddf9-4a29-a6f9-a636f57b4976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>originallink</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>159</td>\n",
       "      <td>&lt;b&gt;전자&lt;/b&gt;랜드, 새해 &amp;apos;&lt;b&gt;삼성전자&lt;/b&gt; 세일 페스타&amp;apos;...</td>\n",
       "      <td>https://www.news1.kr/articles/4922321</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/421/000...</td>\n",
       "      <td>&lt;b&gt;전자&lt;/b&gt;랜드는 이달 22일까지 &amp;apos;&lt;b&gt;삼성전자&lt;/b&gt; 세일 페스타...</td>\n",
       "      <td>Thu, 12 Jan 2023 08:53:00 +0900</td>\n",
       "      <td>15</td>\n",
       "      <td>랜드 - 페스타 - 세일 - 할인 - 동참 - 행사 - 12 - 규모 - 수량 - 한정</td>\n",
       "      <td>(서울=뉴스1) 한지명 기자 = 전자랜드는 이달 22일까지 '삼성전자 세일 페스타'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>160</td>\n",
       "      <td>&amp;quot;55인치 TV 99만원&amp;quot; &lt;b&gt;전자&lt;/b&gt;랜드, &amp;apos;&lt;b...</td>\n",
       "      <td>http://www.newsis.com/view/?id=NISX20230112_00...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>&lt;b&gt;전자&lt;/b&gt;랜드는 &lt;b&gt;삼성전자&lt;/b&gt;에서 진행하는 대규모 할인 행사 ‘&lt;b&gt;...</td>\n",
       "      <td>Thu, 12 Jan 2023 08:39:00 +0900</td>\n",
       "      <td>15</td>\n",
       "      <td>랜드 - 페스타 - 세일 - 할인 - 동참 - 행사 - 12 - 규모 - 수량 - 한정</td>\n",
       "      <td>[서울=뉴시스] 이혜원 기자 = 전자랜드는 삼성전자에서 진행하는 대규모 할인 행사 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                              title  \\\n",
       "141         159  <b>전자</b>랜드, 새해 &apos;<b>삼성전자</b> 세일 페스타&apos;...   \n",
       "142         160  &quot;55인치 TV 99만원&quot; <b>전자</b>랜드, &apos;<b...   \n",
       "\n",
       "                                          originallink  \\\n",
       "141              https://www.news1.kr/articles/4922321   \n",
       "142  http://www.newsis.com/view/?id=NISX20230112_00...   \n",
       "\n",
       "                                                  link  \\\n",
       "141  https://n.news.naver.com/mnews/article/421/000...   \n",
       "142  https://n.news.naver.com/mnews/article/003/001...   \n",
       "\n",
       "                                           description  \\\n",
       "141  <b>전자</b>랜드는 이달 22일까지 &apos;<b>삼성전자</b> 세일 페스타...   \n",
       "142  <b>전자</b>랜드는 <b>삼성전자</b>에서 진행하는 대규모 할인 행사 ‘<b>...   \n",
       "\n",
       "                             pubDate  Topic  \\\n",
       "141  Thu, 12 Jan 2023 08:53:00 +0900     15   \n",
       "142  Thu, 12 Jan 2023 08:39:00 +0900     15   \n",
       "\n",
       "                                          Top_n_words  \\\n",
       "141  랜드 - 페스타 - 세일 - 할인 - 동참 - 행사 - 12 - 규모 - 수량 - 한정   \n",
       "142  랜드 - 페스타 - 세일 - 할인 - 동참 - 행사 - 12 - 규모 - 수량 - 한정   \n",
       "\n",
       "                                               context  \n",
       "141  (서울=뉴스1) 한지명 기자 = 전자랜드는 이달 22일까지 '삼성전자 세일 페스타'...  \n",
       "142  [서울=뉴시스] 이혜원 기자 = 전자랜드는 삼성전자에서 진행하는 대규모 할인 행사 ...  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b821da-f584-482b-a095-41ec523cf2e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "229043b9-67e2-491b-bd3b-649d968bfca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백 정리\n",
    "import re, unicodedata\n",
    "from string import whitespace, punctuation\n",
    "from pykospacing import Spacing\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "def clean_byline(text):\n",
    "    # byline\n",
    "    pattern_email = re.compile(r'[-_0-9a-z]+@[-_0-9a-z]+(?:\\.[0-9a-z]+)+', flags=re.IGNORECASE)\n",
    "    pattern_url = re.compile(r'(?:https?:\\/\\/)?[-_0-9a-z]+(?:\\.[-_0-9a-z]+)+', flags=re.IGNORECASE)\n",
    "    pattern_others = re.compile(r'\\.([^\\.]*(?:기자|특파원|교수|작가|대표|논설|고문|주필|부문장|팀장|장관|원장|연구원|이사장|위원|실장|차장|부장|에세이|화백|사설|소장|단장|과장|기획자|큐레이터|저작권|평론가|©|©|ⓒ|\\@|\\/|=|▶|무단|전재|재배포|금지|\\[|\\]|\\(\\))[^\\.]*)$')\n",
    "    result = pattern_email.sub('', text)\n",
    "    result = pattern_url.sub('', result)\n",
    "\n",
    "    # 본문 시작 전 꺽쇠로 쌓인 바이라인 제거\n",
    "    pattern_bracket = re.compile(r'^((?:\\[.+\\])|(?:【.+】)|(?:<.+>)|(?:◆.+◆)\\s)')\n",
    "    result = pattern_bracket.sub('', result).strip()\n",
    "    return result\n",
    "\n",
    "\n",
    "def text_filter(text): # str -> 전처리 -> 문장 배열\n",
    "    text = clean_byline(text)\n",
    "    exclude_pattern = re.compile(r'[^\\% 0-9a-zA-Zㄱ-ㅣ가-힣.,]+')\n",
    "    exclusions = exclude_pattern.findall(text)\n",
    "    result = exclude_pattern.sub(' ', text).strip()\n",
    "    spacing = Spacing()\n",
    "    kospacing_txt = spacing(result) \n",
    "    sentences = sent_tokenize(kospacing_txt) \n",
    "    return sentences\n",
    "\n",
    "def make_df(name, model):\n",
    "    start = time.time()\n",
    "    df = pd.read_csv(f'../{name}.csv')\n",
    "    text = []\n",
    "    topk = []\n",
    "    for i,context in enumerate(df['context']):\n",
    "        preprocess = text_filter(context)[:60]\n",
    "        text.append([(i,v) for i,v in enumerate(preprocess)])\n",
    "        top = None\n",
    "        if(len(preprocess) > 3):\n",
    "            top = get_topk_sentences(len(preprocess)//4+1, ' '.join(preprocess), model)\n",
    "        if(top):\n",
    "            topk.append(top)\n",
    "        else:\n",
    "            topk.append('Hello world')\n",
    "            \n",
    "    df['text'] = text\n",
    "    df['topk'] = topk\n",
    "    df = df.drop(df[df['topk'] == 'Hello world'].index)\n",
    "    print(f\"{time.time()-start:.4f} sec\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9bc3b03-3f37-4182-a691-8307799d87d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['삼성전자가 갤럭시 버즈 2 프로 소프트웨어 업데이트를 통해 스마트폰 카메라 사용성을 한 단계 더 높였습니다.',\n",
       " '삼성전자는 휴대전화로 동영상을 찍을 때 360도 사운드 녹음이 가능하도록 갤럭시 버즈 2 프로와 갤럭시Z 플립4, 폴드 4의 소프트웨어 업데이트를 시행한다고 밝혔습니다.',\n",
       " '소프트웨어 업데이트를 통해 버즈 2 프로 좌우에 있는 마 이 크로 사용자가 듣는 그대로의 소리를 생생하게 녹음할 수 있다고 삼성전자 측은 설명했습니다.',\n",
       " '당신의 제보가 뉴스가 됩니다 카카오톡 YTN 검색해 채널 추가 전화 02 398 8585 메일']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_filter(\"삼성전자가 갤럭시 버즈2 프로                소프트웨어 업데이트를 통해 스마트폰 카메라 사용성을 한 단계 더 높였습니다. 삼성전자는 휴대전화로 동영상을 찍을 때 360도 사운드 녹음이 가능하도록 갤럭시 버즈2 프로와 갤럭시Z 플립4, 폴드4의 소프트웨어 업데이트를 시행한다고 밝혔습니다. 소프트웨어 업데이트를 통해 버즈2 프로 좌우에 있는 마이크로 사용자가 듣는 그대로의 소리를 생생하게 녹음할 수 있다고 삼성전자 측은 설명했습니다. ※ '당신의 제보가 뉴스가 됩니다' [카카오톡] YTN 검색해 채널 추가 [전화] 02-398-8585 [메일]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "558290c4-688e-4861-a15b-e5a91e2290d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-19 14:45:10,791 INFO] loading archive file ../001_bert_morp_pytorch\n",
      "[2023-01-19 14:45:10,793 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "28.3342 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('../models/bert_classifier2/model_step_35000.pt', map_location=lambda storage, loc: storage)\n",
    "config = BertConfig.from_json_file(args.bert_config_path)\n",
    "model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "    \n",
    "df = make_df('paraphrase_topic15', model)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c540883-931a-4730-b4b2-c0c3f8c3ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다.'),\n",
       " (1, '이에 전자랜드는 오는 2월 12일까지 삼성전자의 제품들을 할인 판매한다.'),\n",
       " (2,\n",
       "  '품목으로는 삼성전자의 55인치 QLED TV를 한 정 판매하고, 이외에 냉장고, 김치냉장고, 에어컨, 세탁기, 건조기, 청소기 등 주요 가전 제품이 있다.'),\n",
       " (3, '할인 기 간에 삼성전자 제품을 구매하면 결제 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다.'),\n",
       " (4, '프리미엄 가전제품은 두 가지 이상 구매 시 최대 450만원의 캐시백을 지급한다.'),\n",
       " (5,\n",
       "  '또한 45개 전자랜드 행사 점에서 1월 13일부터 16일까지 1300만원 이상 결제하면 최대 50만원의 캐시백을 추가 증정한다.'),\n",
       " (6,\n",
       "  '1월 16일부터 31일까지는 삼세권 인증샷 이 벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다.'),\n",
       " (7, '최연성 기자 경제를 읽는 맑은 창 비즈니스플러스')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 19\n",
    "df['text'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26cc4606-9cc4-499d-b677-2a9b4afbbadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, ' 프리미엄 가전제품은 두 가지 이상 구매 시 최대 450만원의 캐시백을 지급한다. '),\n",
       " (5,\n",
       "  ' 또한 45개 전자랜드 행사 점에서 1월 13일부터 16일까지 1300만원 이상 결제하면 최대 50만원의 캐시백을 추가 증정한다. '),\n",
       " (6,\n",
       "  ' 1월 16일부터 31일까지는 삼세권 인증샷 이 벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다. ')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topk'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eac053d2-8a74-4dc3-ac59-5e20e0d48d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../paraphrase_topic15_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b0c12ec-80c6-4915-959d-543e780065af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, ' 행사 기간 프리미엄 가전제품을 두 가지 이상 구매한 고객에게는 캐시백을 지급한다. ')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(str(df['topk'][6]))[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ad25a-431a-4ddc-b991-c9659b49187b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## K-means 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c40b7c-cbbb-444e-a31c-3d61ff83d620",
   "metadata": {},
   "source": [
    "## 토픽 요약하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "072dfe0b-3356-45f3-aea3-5b6350870fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def get_clustered_df(sentences, clusternum):\n",
    "    print(clusternum)\n",
    "    document_df = pd.DataFrame()\n",
    "    document_df['opinion_text'] = [str(t) for t in sentences]\n",
    "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "    lemmar = WordNetLemmatizer()\n",
    "    \n",
    "    # 토큰화한 각 단어들의 원형들을 리스트로 담아서 반환\n",
    "    def LemTokens(tokens):\n",
    "        return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # 텍스트를 Input으로 넣어서 토큰화시키고 토큰화된 단어들의 원형들을 리스트로 담아 반환\n",
    "    def LemNormalize(text):\n",
    "        # .translate인자에 구두점 dict넣어주어서 구두점 삭제해준 상태로 토큰화시키기!\n",
    "        return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize,\n",
    "                            ngram_range=(1,2),\n",
    "                            min_df=0.05, max_df=0.85)\n",
    "\n",
    "    # fit_transform으로 위에서 구축한 도구로 텍스트 벡터화\n",
    "    ftr_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
    "    # K-means로 3개 군집으로 문서 군집화시키기\n",
    "\n",
    "    kmeans = KMeans(n_clusters=clusternum, max_iter=10000, random_state=42)\n",
    "    # 비지도 학습이니 feature로만 학습시키고 예측\n",
    "    cluster_label = kmeans.fit_predict(ftr_vect)\n",
    "    \n",
    "    # 군집화한 레이블값들을 document_df 에 추가하기\n",
    "    document_df['cluster_label'] = cluster_label\n",
    "    return document_df.sort_values(by=['cluster_label'])\n",
    "    \n",
    "\n",
    "def get_topic_sentences(df, clabel):\n",
    "    lst = []\n",
    "    for i,t in enumerate(df[df['cluster_label'] == clabel]['opinion_text']):\n",
    "        print(i, t)\n",
    "        lst.append(t)\n",
    "    return lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c9e30ad-66c3-4f5d-8b45-c01c55dfa431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before delete similar: 20 67\n",
      "after delete similar: 14 39\n"
     ]
    }
   ],
   "source": [
    "def delete_similar(input_sentences):\n",
    "    sorted_sentences = sorted(input_sentences, key=lambda x:x[1])\n",
    "    prev = sorted_sentences[0]\n",
    "    processed_sentences = []\n",
    "    for sentence in sorted_sentences[1:]:\n",
    "        s1 = set(prev[1].split())\n",
    "        s2 = set(sentence[1].split())\n",
    "        actual_jaccard = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "        if(actual_jaccard < 0.45): # if not similar\n",
    "            processed_sentences.append(prev)\n",
    "        prev = sentence\n",
    "        \n",
    "    return processed_sentences\n",
    "\n",
    "\n",
    "def get_first_topk_sentences(name):\n",
    "    df = pd.read_csv(f'../{name}.csv')\n",
    "\n",
    "    first_sentences = []\n",
    "    topk_sentences = []\n",
    "    for a,b in zip(df['text'], df['topk']):\n",
    "        if(eval(str(b))[0][0] == 0):\n",
    "            first_sentences += eval(str(b))[:1]\n",
    "            topk_sentences += eval(str(b))[1:]\n",
    "        else:\n",
    "            first_sentences += eval(str(a))[:1]\n",
    "            topk_sentences += eval(str(b))\n",
    "    \n",
    "    print('before delete similar:', len(first_sentences), len(topk_sentences))\n",
    "    first_sentences = delete_similar(first_sentences)\n",
    "    topk_sentences = delete_similar(topk_sentences)\n",
    "    print('after delete similar:', len(first_sentences), len(topk_sentences))\n",
    "    return first_sentences, topk_sentences\n",
    "\n",
    "first_sentences, topk_sentences = get_first_topk_sentences('paraphrase_topic15_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d58c2890-9bf2-4f00-89f6-cff25aad1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "import random\n",
    "\n",
    "\n",
    "def summarize_topic(document_df, topic_num, tokenizer, model):\n",
    "    sentences = []\n",
    "    numbers = []\n",
    "    for i,t in enumerate(document_df[document_df['cluster_label'] == topic_num]['opinion_text']):\n",
    "        sentences.append(eval(t)[1])\n",
    "        numbers.append(eval(t)[0])\n",
    "    result = make_summarization(sentences, tokenizer, model)\n",
    "    avg = sum(numbers)/len(numbers)\n",
    "    return (avg, result)\n",
    "\n",
    "\n",
    "def make_summarization(sentences, tokenizer, model):\n",
    "    if(len(sentences) < 4): return max(sentences, key=lambda x:len(x))\n",
    "    split = []\n",
    "    for i in range(len(sentences)//8):\n",
    "        split.append(sentences[:8])\n",
    "        sentences = sentences[8:]\n",
    "\n",
    "    for i in range(len(split)):\n",
    "        if(len(sentences) == 0): break\n",
    "        split[i].append(sentences.pop())\n",
    "    \n",
    "    if(len(sentences) != 0): split.append(sentences)\n",
    "    \n",
    "    split_sum = []\n",
    "    for sentences in split:\n",
    "        text = '\\n'.join(sentences)\n",
    "        start = time.time()\n",
    "        raw_input_ids = tokenizer.encode(text)\n",
    "        input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "        summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512, min_length=48,  eos_token_id=1)\n",
    "        print(f\"{time.time()-start:.4f} sec\")\n",
    "        sum_result = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "        print(sum_result)\n",
    "        split_sum.append(sum_result)\n",
    "        print(len(split), len(split_sum))\n",
    "        print('-----------------------------------------------')\n",
    "    \n",
    "    if(len(split_sum)==1):\n",
    "        return split_sum[0]\n",
    "      \n",
    "    return ' '.join(split_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb850187-c03f-4ad4-80a6-b1772f4fb854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')\n",
    "    \n",
    "def summarize_first_sentences(processed_sentences, tokenizer, model):\n",
    "    clusternum = 1\n",
    "    document_df = get_clustered_df(processed_sentences, clusternum)\n",
    "    sum_result = []\n",
    "    for c in range(clusternum):\n",
    "        temp = get_topic_sentences(document_df, c)\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        summ = summarize_topic(document_df, c, tokenizer, model)\n",
    "        sum_result.append(summ)\n",
    "        print(summ)\n",
    "        print('===================================================')\n",
    "    \n",
    "    first_result = (sum_result[0][0], min(sum_result[0][1].split('. '), key=lambda x:len(x)))\n",
    "    return first_result\n",
    "    \n",
    "def summarize_topk_sentences(processed_sentences, tokenizer, model):\n",
    "    clusternum = len(processed_sentences)//7\n",
    "    document_df = get_clustered_df(processed_sentences, clusternum)\n",
    "    sum_result = []\n",
    "    for c in range(clusternum):\n",
    "        temp = get_topic_sentences(document_df, c)\n",
    "        print('---------------------------------------------------')\n",
    "        summ = summarize_topic(document_df, c, tokenizer, model)\n",
    "        sum_result.append(summ)\n",
    "        print(summ)\n",
    "        print('***************************************************')\n",
    "        \n",
    "    return sorted(sum_result, key= lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88992252-f408-458e-bd62-4c6c6d91214d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0, '사진 전자랜드 이 데일리 정병묵 기자 전자랜드가 2대 규모 할인 행사 삼성전자 005930 세일 페스타 에 참여한다고 12일 밝혔다.')\n",
      "1 (0, '사진 전자랜드 제공 데일리 한국 김보라 기자 전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 삼세페 에 동참한다고 12일 밝혔다.')\n",
      "2 (0, '삼성전자 세일 페스타.')\n",
      "3 (0, '서울 뉴스1 한 지명 기자 전자랜드는 이 달 22일까지 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다.')\n",
      "4 (0, '자랜드, 2023년 삼성전자 세일 페스타 동시 운영 전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 삼세페 에 동참한다고 12일 밝혔다.')\n",
      "5 (0, '저작권자 소비자가 만드는 신문 무단 전재 및 재배포 금지 전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성 세일 페스타 에 동참한다고 12일 밝혔다.전자랜드는 오는 2월 12일까지 행사 제품을 한 정 수량으로 할인 판매한다.')\n",
      "6 (0, '전자랜드, 2023년 삼성전자 세일 페스타 동시 운영 전 자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 삼세페 에 동참한다.')\n",
      "7 (0, '전자랜드, 2023년 삼성전자 세일 페스타 동시 운영 제공 전자랜드 열린뉴스통신 ONA 서울 열린뉴스통신 유연수 기자 전자랜드가 2023년 삼성전자 세일 페스타 에 참여한다.')\n",
      "8 (0, '전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다.')\n",
      "9 (0, '전자랜드가 삼성전자 세일 페스타 에 동참한다.')\n",
      "10 (0, '전자랜드는 새해를 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참한다.')\n",
      "11 (0, '최대 450만원의 캐시백 지급하는 다 품목 할인 행사 운영 삼성전자 멤버십 행사에도 동참, SNS 인증하면 멤버십 포인트와 기프티콘 증정 전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참한다.')\n",
      "12 (0, '최연혁 스웨덴 린네 대 교수 스웨덴 예테보리대학 미디어연구소에서는 1997년 이후부터 매년 스웨덴의 공공기관과 시장 주요 행위자에 대한 신뢰도를 측정해 발표한다. ')\n",
      "13 (0, '카카오톡 으 로 기사 보내기 URL 복사 으 로 기사 보내기 전자랜드가 삼성전자 세일 페스타 에 동참한다.')\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2.0856 sec\n",
      "전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 005930 세일 페스타 에 동참한다고 12일 밝혔으며 전자랜드는 오는 2월 12일까지 행사 제품을 한 정 수량으로 할인하였고, 전자랜드는 이 달 22일까지 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다.\n",
      "2 1\n",
      "-----------------------------------------------\n",
      "2.1905 sec\n",
      "전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다.\n",
      "전자랜드는 새해를 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참하며, 새해를 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참하며, 다 품목 할인 행사 운영 삼성전자 멤버십 행사에도 동참한다.\n",
      "2 2\n",
      "-----------------------------------------------\n",
      "(0.0, '전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 005930 세일 페스타 에 동참한다고 12일 밝혔으며 전자랜드는 오는 2월 12일까지 행사 제품을 한 정 수량으로 할인하였고, 전자랜드는 이 달 22일까지 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다. 전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다.\\n전자랜드는 새해를 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참하며, 새해를 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 세일 페스타 에 동참하며, 다 품목 할인 행사 운영 삼성전자 멤버십 행사에도 동참한다.')\n",
      "===================================================\n",
      "5\n",
      "0 (6, ' 13일부터 16일까지 45개의 전자랜드 행사 점에서 다 품목을 구매하면 캐시백을 추가 증정한다 . ')\n",
      "1 (6, ' 또한 이 달 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만 원의 캐시백을 추가 증정한다. ')\n",
      "2 (5, ' 또한 45개 전자랜드 행사 점에서 1월 13일부터 16일까지 1300만원 이상 결제하면 최대 50만원의 캐시백을 추가 증정한다. ')\n",
      "3 (6, ' 또한 1월 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만원 이상의 다 품목을 구매하면 최대 50만원의 캐시백을 추가 증정한다. ')\n",
      "4 (6, ' 또 이달 13일부터 16일까지 전자랜드 45개 행사점에서 1300만원 이상의 다 품목을 구매하면 최대 50만원의 캐시백을 추가 증정한 다. ')\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8788 sec\n",
      "이 달 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만 원의 캐시백을 추가 증정한다. 블룸 또한 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만원의 캐시백을 추가 증정한다.\n",
      "1 1\n",
      "-----------------------------------------------\n",
      "(5.8, '이 달 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만 원의 캐시백을 추가 증정한다. 블룸 또한 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만원의 캐시백을 추가 증정한다.')\n",
      "***************************************************\n",
      "0 (8, ' 또한 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다. ')\n",
      "1 (8, ' 또 1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다. ')\n",
      "2 (8, ' 또한 1월 16일부터 31일까지는 삼세권 인증샷 행사를 진행해 삼성전자  세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다. ')\n",
      "3 (6, ' 1월 16일부터 31일까지는 삼세권 인증샷 이 벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다. ')\n",
      "---------------------------------------------------\n",
      "2.1918 sec\n",
      "1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정하며 1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다.\n",
      "1 1\n",
      "-----------------------------------------------\n",
      "(7.5, '1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정하며 1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다.')\n",
      "***************************************************\n",
      "0 (11, ' 노조가 총파업에 들어 갈 경우 국민들의 일반적 시선은 그들의 당연한 권리로 받아들인다. ')\n",
      "1 (10, ' 스웨덴 국민들의 노조에 대한 신뢰는 특별하다 . ')\n",
      "2 (8, '전자랜드 관계자는 2023년 1월은 신 년맞이 및 설 명절 기념 선물 수요로 인해 가전제품 구매가 늘어날 것으로 예상한 다 라며, 삼세페는 전자 랜드의 1월 할인 혜택 및 이벤트와 동시 운영되니 가전 교체 및 신규 구매를 계획하고 있다면 이번이 좋은 기회가 될 것 이라고 말했다. ')\n",
      "3 (5, ' 그 중에서도 특히 눈에 띄는 것은 꾸준하게 유지된 국민들의 노조에 대한 긍정적 시각이다. ')\n",
      "4 (8, '전자랜드 관계자는 1월은 신년맞이 및 설 명절 기념 선물 수요로 인해 가전제품 구매가 늘어날 것으로 예상한 다 고 전했다. ')\n",
      "5 (11, ' 또한, 2023년 보험시장을 전망하면서 성장 둔화에 대비하여 어떻게 새로운 가망 고객을 발굴하여 수익성을 창출해 나갈 것인지 초대 강의를 통해 통찰하는 시간을 가져 좋은 반응을 얻었다. ')\n",
      "6 (6, ' 전자랜드 관계자는 2023년 1월은 신년맞이 및 설 명절 기념 선물 수요로 인해 가전제품 구매 가 늘어날 것으로 예상한 다 라며, 삼세페는 전자 랜드의 1월 할인 혜택 및 이벤트와 동시 운영되니 가전 교체 및 신규 구매를 계획하고 있다면 이번이 좋은 기회가 될 것 이라고 말했다. ')\n",
      "7 (4, ' 2022년은 코로나 이후 일상으로의 복귀, 러시아의 우크라이나 침공, 에너지 위기 및 원자재 수급의 불안으로 야기된 물가 상승, 그리고 시중금리 인상 등으로 국민들의 안전에 대한 위기의식과 경 제적 불안이 가중되었지만, 관련 기관들의 비상관리 능력에 대한 긍정적 평가를 읽을 수 있다. ')\n",
      "8 (6, ' 22퍼센트 수준으로 가장 낮았던 2016년 이후 꾸준히 성장해 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다. ')\n",
      "9 (13, ' 3년마다 한 번씩 찾아오는 중앙임금교섭 기간 동안 양측의 임금 인상안에 대한 입장 차이가 현격히 클 때 국민들은 협상이 결렬될 것에 대비 해  마음의 준비를 단단히 한다. ')\n",
      "10 (2, ' 각 기관들의 한 해 동안의 활동에 대한 국민의 평가를 담고 있기 때 문이다. ')\n",
      "11 (9, ' 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표다. ')\n",
      "12 (10, ' 전화 02 777 0003 이메일 카카오톡 한 강타임즈 저작권자 내 손안의 뉴스 한 강타임즈 무단 전재 및 재배포 금지 응원해주세요. ')\n",
      "---------------------------------------------------\n",
      "3.2224 sec\n",
      "스웨덴 국민들의가 총파업에 들어 갈 경우 국민들의 일반적 시선은 그들의 당연한 권리로 받아들이고 있으며, 특히 꾸준하게 유지된 국민들의 노조에 대한 긍정적 시각으로 인해 스웨덴 국민들의 노조에 대한 신뢰는 특별하다.  \n",
      "전자랜드 관계자는 2023년 1월은 신 년맞이 및 설 명절 기념 선물 수요로 인해 가전제품 구매가 늘어날 것으로 예상한 다 라며, 삼세페는 전자 랜드의 1월 할인 혜택 및 이벤트와 동시 운영되니 가전 교체 및 신규 구매를 계획하고 있다면 이번이 좋은 기회가 될 것 이라고 말했다.\n",
      "2 1\n",
      "-----------------------------------------------\n",
      "2.4690 sec\n",
      "2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.  \n",
      " 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.\n",
      "2 2\n",
      "-----------------------------------------------\n",
      "(7.923076923076923, '스웨덴 국민들의가 총파업에 들어 갈 경우 국민들의 일반적 시선은 그들의 당연한 권리로 받아들이고 있으며, 특히 꾸준하게 유지된 국민들의 노조에 대한 긍정적 시각으로 인해 스웨덴 국민들의 노조에 대한 신뢰는 특별하다.  \\n전자랜드 관계자는 2023년 1월은 신 년맞이 및 설 명절 기념 선물 수요로 인해 가전제품 구매가 늘어날 것으로 예상한 다 라며, 삼세페는 전자 랜드의 1월 할인 혜택 및 이벤트와 동시 운영되니 가전 교체 및 신규 구매를 계획하고 있다면 이번이 좋은 기회가 될 것 이라고 말했다. 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.  \\n 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.')\n",
      "***************************************************\n",
      "0 (5, ' 행사 기간 프리미엄 가전제품을 두 가지 이상 구매한 고객에게는 캐시백을 지급한다. ')\n",
      "1 (8, ' 행사 기간 삼성전자 제품을 구매한 고객들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다. ')\n",
      "2 (4, ' 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객에게는 최대 450만원의 캐시백을 지급한다. ')\n",
      "3 (8, ' 행사 기간 동안 삼성전자 제품을 구매한 고객들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다. ')\n",
      "4 (4, ' 프리미엄 가전제품을 두 가지 이상 구매한 고객에 게는 최대 450만원의 캐시백을 지급한다. ')\n",
      "5 (12, ' 직장 동료들과 이웃들과 이야기 할 때 노조 파업에 대해 물어 보면 그럴 이유가 충분히 있겠지 정도로 받아 들이는 것이 대다수다. ')\n",
      "6 (6, ' 삼성전자 제품을 구매한 고객들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다. ')\n",
      "7 (1, ' 작년까지 총 25회 연속으로 진행되어 연구자 뿐 아니라 스웨덴의 각 기관들은 매년 여론조사가 발표될 때마다 큰 관심을 갖는다. ')\n",
      "8 (8, ' 이런 기관과 나란히 어깨를 하고 있는 것이 노조 인 셈이다. ')\n",
      "9 (3, ' 신뢰도의 최근 변화를 보면 병원과 의료기관이 최고의 높은 점수를 받고 있고, 경찰, 대학, 법원, 중앙은행, 국가, 의회의 순으로 높은 신뢰도를 보여준다. ')\n",
      "10 (7, ' 스웨덴 교회는 2000년부터 국가와  분리되었지만 여전히 국민들이 어렵고 힘들 때 기대고 찾아가는 중요한 사회적 구심점 역할을 한다. ')\n",
      "11 (4, ' 또한 행사 기간 동안 삼성전자 제품을 구매한 고객 들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다. ')\n",
      "---------------------------------------------------\n",
      "1.5828 sec\n",
      "삼성전자는 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들에게 최대 450만원의 캐시백을 지급하며, 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다.\n",
      "2 1\n",
      "-----------------------------------------------\n",
      "2.0080 sec\n",
      "스웨덴 교회는 2000년부터 국가와  분리되었지만 여전히 국민들이 어렵고 힘들 때 기대고 찾아가는 중요한 사회적 구심점 역할을 하고  있으며 이러한 기관과 나란히 어깨를 나란히 하고 있는 것이 노조 인 셈이다.  \n",
      " 신뢰도의 최근 변화를 보면 병원과 의료기관이 최고의 높은 점수를 받고 있고, 경찰, 대학, 법원, 중앙은행, 국가, 의회의 순으로 높은 신뢰도를 보여준다.\n",
      "2 2\n",
      "-----------------------------------------------\n",
      "(5.833333333333333, '삼성전자는 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들에게 최대 450만원의 캐시백을 지급하며, 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다. 스웨덴 교회는 2000년부터 국가와  분리되었지만 여전히 국민들이 어렵고 힘들 때 기대고 찾아가는 중요한 사회적 구심점 역할을 하고  있으며 이러한 기관과 나란히 어깨를 나란히 하고 있는 것이 노조 인 셈이다.  \\n 신뢰도의 최근 변화를 보면 병원과 의료기관이 최고의 높은 점수를 받고 있고, 경찰, 대학, 법원, 중앙은행, 국가, 의회의 순으로 높은 신뢰도를 보여준다.')\n",
      "***************************************************\n",
      "0 (6, ' 전자랜드는 삼성전자 멤버십 행사에도 동참한다. ')\n",
      "1 (4, ' 여러 가전제품을 구매하면 혜택을 제공하는 다 품목 할인 행사도 운영한다. ')\n",
      "2 (6, ' 삼성전자 멤버십 행사에도 동참한다. ')\n",
      "3 (4, ' 전자랜드는 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다. ')\n",
      "4 (6, '전자랜드는 삼성전자 멤버십 행사에도 동참한다. ')\n",
      "---------------------------------------------------\n",
      "1.6662 sec\n",
      "여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.  \n",
      "전자랜드는 삼성전자 멤버십 행사에도 동참하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.\n",
      "1 1\n",
      "-----------------------------------------------\n",
      "(5.2, '여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.  \\n전자랜드는 삼성전자 멤버십 행사에도 동참하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.')\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "sum_result1 = summarize_first_sentences(first_sentences, tokenizer, model)\n",
    "sum_result2 = summarize_topk_sentences(topk_sentences, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6290952b-60e9-485b-af7b-5cb937241307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " '전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 005930 세일 페스타 에 동참한다고 12일 밝혔으며 전자랜드는 오는 2월 12일까지 행사 제품을 한 정 수량으로 할인하였고, 전자랜드는 이 달 22일까지 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6299d47-dd9a-408f-a78f-4ed10faa38df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.2,\n",
       "  '여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.  \\n전자랜드는 삼성전자 멤버십 행사에도 동참하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.'),\n",
       " (5.8,\n",
       "  '이 달 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만 원의 캐시백을 추가 증정한다. 블룸 또한 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만원의 캐시백을 추가 증정한다.'),\n",
       " (5.833333333333333,\n",
       "  '삼성전자는 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들에게 최대 450만원의 캐시백을 지급하며, 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다. 스웨덴 교회는 2000년부터 국가와  분리되었지만 여전히 국민들이 어렵고 힘들 때 기대고 찾아가는 중요한 사회적 구심점 역할을 하고  있으며 이러한 기관과 나란히 어깨를 나란히 하고 있는 것이 노조 인 셈이다.  \\n 신뢰도의 최근 변화를 보면 병원과 의료기관이 최고의 높은 점수를 받고 있고, 경찰, 대학, 법원, 중앙은행, 국가, 의회의 순으로 높은 신뢰도를 보여준다.'),\n",
       " (7.5,\n",
       "  '1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정하며 1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다.'),\n",
       " (7.923076923076923,\n",
       "  '스웨덴 국민들의가 총파업에 들어 갈 경우 국민들의 일반적 시선은 그들의 당연한 권리로 받아들이고 있으며, 특히 꾸준하게 유지된 국민들의 노조에 대한 긍정적 시각으로 인해 스웨덴 국민들의 노조에 대한 신뢰는 특별하다.  \\n전자랜드 관계자는 2023년 1월은 신 년맞이 및 설 명절 기념 선물 수요로 인해 가전제품 구매가 늘어날 것으로 예상한 다 라며, 삼세페는 전자 랜드의 1월 할인 혜택 및 이벤트와 동시 운영되니 가전 교체 및 신규 구매를 계획하고 있다면 이번이 좋은 기회가 될 것 이라고 말했다. 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.  \\n 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9278cd09-36a3-4275-ae7d-a495d9bd349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 005930 세일 페스타 에 동참한다고 12일 밝혔으며 전자랜드는 오는 2월 12일까지 행사 제품을 한 정 수량으로 할인하였고, 전자랜드는 이 달 22일까지 삼성전자 세일 페스타 에 동참한다고 12일 밝혔다. ',\n",
       " (1,\n",
       "  '여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.  \\n전자랜드는 삼성전자 멤버십 행사에도 동참하며 여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도 운영한다.'),\n",
       " (2,\n",
       "  '이 달 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만 원의 캐시백을 추가 증정한다. 블룸 또한 45개의 전자랜드 행사점에서 1300만 원  이상의 다 품목을 구매하면 최대 50만원의 캐시백을 추가 증정한다.'),\n",
       " (3,\n",
       "  '삼성전자는 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들에게 최대 450만원의 캐시백을 지급하며, 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들은 구매 금액의 최대 3배를 삼성전자 멤버십 포인트로 환급 받을 수 있다. 스웨덴 교회는 2000년부터 국가와  분리되었지만 여전히 국민들이 어렵고 힘들 때 기대고 찾아가는 중요한 사회적 구심점 역할을 하고  있으며 이러한 기관과 나란히 어깨를 나란히 하고 있는 것이 노조 인 셈이다.  \\n 신뢰도의 최근 변화를 보면 병원과 의료기관이 최고의 높은 점수를 받고 있고, 경찰, 대학, 법원, 중앙은행, 국가, 의회의 순으로 높은 신뢰도를 보여준다.'),\n",
       " (4,\n",
       "  '1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정하며 1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일 페스타의 판촉물을 찍은 사진을 개인 SNS에 업로드하면 추첨을 통해 치킨 기프티콘을 증정한다.'),\n",
       " (5,\n",
       "  '스웨덴 국민들의가 총파업에 들어 갈 경우 국민들의 일반적 시선은 그들의 당연한 권리로 받아들이고 있으며, 특히 꾸준하게 유지된 국민들의 노조에 대한 긍정적 시각으로 인해 스웨덴 국민들의 노조에 대한 신뢰는 특별하다.  \\n전자랜드 관계자는 2023년 1월은 신 년맞이 및 설 명절 기념 선물 수요로 인해 가전제품 구매가 늘어날 것으로 예상한 다 라며, 삼세페는 전자 랜드의 1월 할인 혜택 및 이벤트와 동시 운영되니 가전 교체 및 신규 구매를 계획하고 있다면 이번이 좋은 기회가 될 것 이라고 말했다. 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.  \\n 2022년 국민들의 노조에 대한 신뢰도는 정당, 대기업, 은행 들보다도 높은 수준으로 노조를 긍정적인 시장 주체로 인정하고 있다는 것을 잘 보여주는 지표로 2022년 조사에서는 스웨덴 교회와 동일한 수준의 신뢰도를 보여주고 있다.')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = [v for i,v in [sum_result1] + sum_result2]\n",
    "final_sentences = [(i,s) if '.' in s[-2: ] else s+'. ' for i,s in enumerate(final_result)]\n",
    "final_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7bdbaf14-e519-4b29-a65f-8da2d78c78e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 005...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, '여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2, '이 달 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만 원  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3, '삼성전자는 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4, '1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(5, '스웨덴 국민들의가 총파업에 들어 갈 경우 국민들의 일반적 시선은 그들의 당...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        opinion_text  cluster_label\n",
       "0  전자랜드가 2023년을 맞아 삼성전자에서 진행하는 대규모 할인 행사 삼성전자 005...              0\n",
       "1  (1, '여러 가지 가전제품을 구매하면 풍성한 혜택을 제공하는 다 품목 할인 행사도...              0\n",
       "2  (2, '이 달 13일부터 16일까지 45개의 전자랜드 행사점에서 1300만 원  ...              0\n",
       "3  (3, '삼성전자는 행사 기간 동안 프리미엄 가전제품을 두 가지 이상 구매한 고객들...              0\n",
       "4  (4, '1월 16일부터 31일까지는 삼세권 인증샷 이벤트 를 진행해 삼성전자 세일...              0\n",
       "5  (5, '스웨덴 국민들의가 총파업에 들어 갈 경우 국민들의 일반적 시선은 그들의 당...              0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusternum = len(final_sentences)//7 + 1\n",
    "final_cluster_df = get_clustered_df(final_sentences, clusternum)\n",
    "final_cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "741584b6-69d4-487d-8b5e-7b51eb47b911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "00412487-e17e-43d2-a615-c7351700f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-19 06:23:45,517 INFO] loading archive file ../001_bert_morp_pytorch\n",
      "[2023-01-19 06:23:45,519 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30349\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('../models/bert_classifier2/model_step_35000.pt', map_location=lambda storage, loc: storage)\n",
    "config = BertConfig.from_json_file(args.bert_config_path)\n",
    "model2 = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "08151b70-f352-4ff9-acb2-ed3836211fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load('../models/bert_classifier2/model_step_35000.pt', map_location=lambda storage, loc: storage)\n",
    "#config = BertConfig.from_json_file(args.bert_config_path)\n",
    "#model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "def make_summarization_final(sentences, model):\n",
    "    if(len(sentences) < 4): return max(sentences, key=lambda x:len(x))\n",
    "    split = []\n",
    "    for i in range(len(sentences)//8):\n",
    "        split.append(sentences[:8])\n",
    "        sentences = sentences[8:]\n",
    "\n",
    "    for i in range(len(split)):\n",
    "        if(len(sentences) == 0): break\n",
    "        split[i].append(sentences.pop())\n",
    "    \n",
    "    if(len(sentences) != 0): split.append(sentences)\n",
    "    \n",
    "    split_sum = []\n",
    "    for sentences in split:\n",
    "        text = '\\n'.join(sentences)\n",
    "        start = time.time()\n",
    "        sent = get_topk_sentences(len(sentences)//2, ' '.join(sentences), model) \n",
    "        print(f\"{time.time()-start:.4f} sec\")\n",
    "        print(sent)\n",
    "        split_sum += sent\n",
    "        print(len(split), len(split_sum))\n",
    "        print('-----------------------------------------------')\n",
    "    \n",
    "    if(len(split_sum)==1):\n",
    "        return split_sum[0]\n",
    "      \n",
    "    return split_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fcf48200-b2c8-4a63-b540-ea888e1eb97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1.6871 sec\n",
      "[(3, '   TSMC는 지난해 같은 기간 대비 매출을 43% 가량 늘리며 세계 반도체 매출 1위는 유지한 것으로 추정되나, TSMC는 지난해 3분기에 이어 4분기에도 세계 반도체 매출 1위는 유지한 것으로 추정된다. '), (4, '  세계 1위 파운드리업체인 TSMC 매출에서 데이터 서버 등에 사용되는 고성능 컴퓨터용 반도체가 1위에 올라섰다는 점은 세계 파운드리 시장의 판도 변화를 보여주는 중요한 의미가 있다. '), (5, '  \\n웨이저자 TSMC CEO 는 12일 콘퍼런스콜을 통해 3나노 미세공정에서 고성능 컴퓨터용 반도체 고객사 수요가 공급 능력을 웃도는 상황을 보이고 있다며, 2023년 하반기부터 매출에 상당한 부분을 기여하게 될 것 이라고 밝혔다. '), (8, ' 마이크론은 인력 구조조정에도 나섰으며 전년 대비 각각 %, % 감소한 규모인 매출 증가율은 10%로 집계됐다. ')]\n",
      "3 4\n",
      "-----------------------------------------------\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1.7091 sec\n",
      "[(2, '                                                                   . '), (3, '  세계적인 경기 침체 우려 속에 글로벌 반도체 기업인 삼성전자와 TSMC의 실적 온도 차의 원인을 파운드리 사업의 수 주 경쟁력에서 찾고 있는 가운데, 삼성전자는 파운드리 업체가 보유한 공정 기술과 특허를 반영해 반도체를 설계하기 때문에 경기 부진의 여파를 상대적으로 비껴 간 것으로 보인다. '), (4, ' 삼성전자는 메모 메모리 반도체와 파운드리를 모두 운영하는 사업자인데 메모리 반도체 업황 침체로 분 기 매출 1위를  되찾지 못하였으며 이는 고금리 영향으로 글로벌 IT 기업들이 투자를 축소하고 스마트폰과 PC 등의 수요가 줄어들자 직격탄을 맞았기 때문이다. '), (7, '   삼성전자는 오는 31일 2022년 4분기 및 연간 실적을 발표하는 가운데 시장에선 반도 체 부문 매출액을 19조 3천억 원 수준으로 보고 있으며 삼성전자는 잠정 실적 발표를 통해 2 022년 4분기 매출 70조원, 영업이익 4조3000억원을 기록했다고 밝혔다. ')]\n",
      "3 8\n",
      "-----------------------------------------------\n",
      "using cached model. /opt/ml/KorBertSum/src/./tmp/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /opt/ml/KorBertSum/src/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "1.6510 sec\n",
      "[(3, ' 삼성전자는 갤럭시 달 중순 갤럭시 북 2 프로 360 신제품을 선 보였으며 이 달 중순 갤럭시 북 2 프로 360 신제품을 선 보였다. '), (5, '  뉴욕증시는 대형 은행주들의 약화한 실적 발표와 경기침체 경고 메시지에도 불구하고 인플레이션 완화 기대감이 이어지며 일제히 상승했다. '), (9, '  \\n 앞서 TSMC에 1위 자리를 내준 삼성전자가 메모리 시장 침체 여파로 부진했기 때문인데요. '), (10, ' \\n 반도체 분야는 기업 간 M A가 매우 활발한 영역으로  호환 인증 받은 DDR5 D램은 서버용 메모리 반도체로, 주로 데이터센터 업체들이 채택합니다. ')]\n",
      "3 12\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3,\n",
       "  '   TSMC는 지난해 같은 기간 대비 매출을 43% 가량 늘리며 세계 반도체 매출 1위는 유지한 것으로 추정되나, TSMC는 지난해 3분기에 이어 4분기에도 세계 반도체 매출 1위는 유지한 것으로 추정된다. '),\n",
       " (4,\n",
       "  '  세계 1위 파운드리업체인 TSMC 매출에서 데이터 서버 등에 사용되는 고성능 컴퓨터용 반도체가 1위에 올라섰다는 점은 세계 파운드리 시장의 판도 변화를 보여주는 중요한 의미가 있다. '),\n",
       " (5,\n",
       "  '  \\n웨이저자 TSMC CEO 는 12일 콘퍼런스콜을 통해 3나노 미세공정에서 고성능 컴퓨터용 반도체 고객사 수요가 공급 능력을 웃도는 상황을 보이고 있다며, 2023년 하반기부터 매출에 상당한 부분을 기여하게 될 것 이라고 밝혔다. '),\n",
       " (8, ' 마이크론은 인력 구조조정에도 나섰으며 전년 대비 각각 %, % 감소한 규모인 매출 증가율은 10%로 집계됐다. '),\n",
       " (2, '                                                                   . '),\n",
       " (3,\n",
       "  '  세계적인 경기 침체 우려 속에 글로벌 반도체 기업인 삼성전자와 TSMC의 실적 온도 차의 원인을 파운드리 사업의 수 주 경쟁력에서 찾고 있는 가운데, 삼성전자는 파운드리 업체가 보유한 공정 기술과 특허를 반영해 반도체를 설계하기 때문에 경기 부진의 여파를 상대적으로 비껴 간 것으로 보인다. '),\n",
       " (4,\n",
       "  ' 삼성전자는 메모 메모리 반도체와 파운드리를 모두 운영하는 사업자인데 메모리 반도체 업황 침체로 분 기 매출 1위를  되찾지 못하였으며 이는 고금리 영향으로 글로벌 IT 기업들이 투자를 축소하고 스마트폰과 PC 등의 수요가 줄어들자 직격탄을 맞았기 때문이다. '),\n",
       " (7,\n",
       "  '   삼성전자는 오는 31일 2022년 4분기 및 연간 실적을 발표하는 가운데 시장에선 반도 체 부문 매출액을 19조 3천억 원 수준으로 보고 있으며 삼성전자는 잠정 실적 발표를 통해 2 022년 4분기 매출 70조원, 영업이익 4조3000억원을 기록했다고 밝혔다. '),\n",
       " (3,\n",
       "  ' 삼성전자는 갤럭시 달 중순 갤럭시 북 2 프로 360 신제품을 선 보였으며 이 달 중순 갤럭시 북 2 프로 360 신제품을 선 보였다. '),\n",
       " (5,\n",
       "  '  뉴욕증시는 대형 은행주들의 약화한 실적 발표와 경기침체 경고 메시지에도 불구하고 인플레이션 완화 기대감이 이어지며 일제히 상승했다. '),\n",
       " (9, '  \\n 앞서 TSMC에 1위 자리를 내준 삼성전자가 메모리 시장 침체 여파로 부진했기 때문인데요. '),\n",
       " (10,\n",
       "  ' \\n 반도체 분야는 기업 간 M A가 매우 활발한 영역으로  호환 인증 받은 DDR5 D램은 서버용 메모리 반도체로, 주로 데이터센터 업체들이 채택합니다. ')]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sum = make_summarization_final(final_result, model2)\n",
    "final_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e41767-b102-4861-8fae-7f4cd86349e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 생성 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4dcb631d-d646-4bb8-b340-d2ece294fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "import random\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')\n",
    "\n",
    "def make_summarization(sentences):\n",
    "    text = '\\n'.join(sentences)\n",
    "    start = time.time()\n",
    "    raw_input_ids = tokenizer.encode(text)\n",
    "    input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "    summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512, min_length=64,  eos_token_id=1)\n",
    "    print(f\"{time.time()-start:.4f} sec\")\n",
    "    sum_result = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "    return sum_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4072020a-40c0-45a5-afe4-dc7bb57be7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "import random\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')\n",
    "\n",
    "def summarize_topic(document_df, topic_num):\n",
    "    sentences = []\n",
    "    numbers = []\n",
    "    for i,t in enumerate(document_df[document_df['cluster_label'] == topic_num]['opinion_text']):\n",
    "        sentences.append(eval(t)[1])\n",
    "        numbers.append(eval(t)[0])\n",
    "    result = make_summarization(sentences)\n",
    "    avg = sum(numbers)/len(numbers)\n",
    "    return (avg, result)\n",
    "\n",
    "def make_summarization(sentences, tokenizer, model):\n",
    "    if(len(sentences) < 4): return max(sentences, key=lambda x:len(x))\n",
    "    split = []\n",
    "    for i in range(len(sentences)//8):\n",
    "        split.append(sentences[:8])\n",
    "        sentences = sentences[8:]\n",
    "\n",
    "    for i in range(len(split)):\n",
    "        if(len(sentences) == 0): break\n",
    "        split[i].append(sentences.pop())\n",
    "    \n",
    "    if(len(sentences) != 0): split.append(sentences)\n",
    "    \n",
    "    split_sum = []\n",
    "    for sentences in split:\n",
    "        text = '\\n'.join(sentences)\n",
    "        start = time.time()\n",
    "        raw_input_ids = tokenizer.encode(text)\n",
    "        input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "        summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512, min_length=48,  eos_token_id=1)\n",
    "        print(f\"{time.time()-start:.4f} sec\")\n",
    "        sum_result = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "        print(sum_result)\n",
    "        split_sum.append(sum_result)\n",
    "        print(len(split), len(split_sum))\n",
    "        print('-----------------------------------------------')\n",
    "    \n",
    "    if(len(split_sum)==1):\n",
    "        return split_sum[0]\n",
    "      \n",
    "    return ' '.join(split_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c285b662-3924-4e35-8856-390a845d80f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>(5, ' 특히 최근 주목받고 있는 자동차용 반도체, 인공지능 AI , 사물인터넷 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>(5, ' 비즈니스 포스트 글로벌 경제팀에서 연재하는 삼성의 라이벌 기획은 삼성전자...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>(5, ' 특히 이 반도체는 단독이 아닌 CPU와 함께 쓰여 CPU 업체로부터 인증...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(5, ' 6 삼성전자 파운드리 분사 준비됐나, 고객사와 경쟁 한계 비즈니스포스트 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>(5, ' 지난해 363억달러 보다 시설 투자액을 최대 % 줄이겠다 고 선언한 것이...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>(12, ' 인도네시아는 오랜 기간 테슬라 공장 유치를 추진해 왔습니다. ')</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(12, ' DDR 뒤에 붓는 숫자가 높을수록 차세대 제품이며, 숫자가 높아질 때마...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>(12, ' 미국 텍 사스주 테일 러시에 건설 중인 삼성전자 신규 파운드리 공장. ')</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>(12, '장중 머우 창업주의  표현은 다소 거칠었지만, 그가 세계화 및 자유무역 ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>(12, ' 영국 이코노미스트는 TSMC 가 처음 애플의 반도체 위탁 생산을 수주한...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          opinion_text  cluster_label\n",
       "150  (5, ' 특히 최근 주목받고 있는 자동차용 반도체, 인공지능 AI , 사물인터넷 ...              0\n",
       "71   (5, ' 비즈니스 포스트 글로벌 경제팀에서 연재하는 삼성의 라이벌 기획은 삼성전자...              0\n",
       "148  (5, ' 특히 이 반도체는 단독이 아닌 CPU와 함께 쓰여 CPU 업체로부터 인증...              0\n",
       "8    (5, ' 6 삼성전자 파운드리 분사 준비됐나, 고객사와 경쟁 한계 비즈니스포스트 ...              0\n",
       "137  (5, ' 지난해 363억달러 보다 시설 투자액을 최대 % 줄이겠다 고 선언한 것이...              0\n",
       "..                                                 ...            ...\n",
       "121        (12, ' 인도네시아는 오랜 기간 테슬라 공장 유치를 추진해 왔습니다. ')             24\n",
       "11   (12, ' DDR 뒤에 붓는 숫자가 높을수록 차세대 제품이며, 숫자가 높아질 때마...             24\n",
       "58    (12, ' 미국 텍 사스주 테일 러시에 건설 중인 삼성전자 신규 파운드리 공장. ')             24\n",
       "174  (12, '장중 머우 창업주의  표현은 다소 거칠었지만, 그가 세계화 및 자유무역 ...             24\n",
       "117  (12, ' 영국 이코노미스트는 TSMC 가 처음 애플의 반도체 위탁 생산을 수주한...             24\n",
       "\n",
       "[176 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1bf3c8aa-5bfa-4e09-959a-a4cc426e0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_topic(document_df, topic_num):\n",
    "    sentences = []\n",
    "    numbers = []\n",
    "    for i,t in enumerate(document_df[document_df['cluster_label'] == topic_num]['opinion_text']):\n",
    "        sentences.append(eval(t)[1])\n",
    "        numbers.append(eval(t)[0])\n",
    "    result = make_summarization(sentences)\n",
    "    avg = sum(numbers)/len(numbers)\n",
    "    return (avg, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cfbc7d4b-8747-4b84-abfe-9788bca09192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3943 sec\n",
      "대만 T운드리 위탁 생산 글로벌 1위인 대만 TSMC가 지난해 3분기에 이어 4분기에도 삼성전자를 꺾고 세계 반도체 매출 1위에 오른 소식에도, 하반기 반도체 업황 반등 기대감이 작용해 삼성전자 주가는 소폭 상승하고 있다.  \n",
      "2 1\n",
      "-----------------------------------------------\n",
      "1.2878 sec\n",
      "TSMC는 지난해 같은 기간 대비 매출을 43% 가량 늘리며 세계 반도체 매출 1위는 유지한 것으로 추정되나, TSMC는 지난해 3분기에 이어 4분기에도 세계 반도체 매출 1위는 유지한 것으로 추정된다. \n",
      "2 2\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.363636363636363,\n",
       " '대만 T운드리 위탁 생산 글로벌 1위인 대만 TSMC가 지난해 3분기에 이어 4분기에도 삼성전자를 꺾고 세계 반도체 매출 1위에 오른 소식에도, 하반기 반도체 업황 반등 기대감이 작용해 삼성전자 주가는 소폭 상승하고 있다.   TSMC는 지난해 같은 기간 대비 매출을 43% 가량 늘리며 세계 반도체 매출 1위는 유지한 것으로 추정되나, TSMC는 지난해 3분기에 이어 4분기에도 세계 반도체 매출 1위는 유지한 것으로 추정된다. ')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = summarize_topic(document_df, 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1e0e90f0-7a0b-46ce-bc5f-2d5cf010ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5, ' 하지만 올해는 수익성, 재고 문제 등으로 인해 이어폰 신제품을 출시하지 않을 예정이다. ')\n",
      "1 (6, ' 딜 사이트 김민기 기자 삼성전자의 새로운 먹거리로 보였던  무선 이어폰이 애플이라는 큰 벽과 중국 기업의 저가 공세를 막지 못하면서 어려움을 겪고 있다. ')\n",
      "2 (7, ' 신제품 대신 업데이트로 대응 업계에서는 올해 삼성전자의 무선 이어폰 신제품 출시는 없을 것으로 전망하고 있다. ')\n",
      "3 (15, ' 하지만 이번에는 소프트웨어 업데이트 이외에  새로운 신제품 출시는 이뤄지지 않는다. ')\n",
      "4 (16, ' 삼성전자 관계자는 갤럭시 버즈 2 신제품 나온 지가 6개월 밖에 안 된 상황 이라며 올해 신제품 출시와 관련해서는 아직 잘 모르겠다 고 답했다. ')\n",
      "5 (15, ' 해당 기능은 원 UI 소프트웨어 지원 스마트폰과 연동해 이 용할 수 있다. ')\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for i,t in enumerate(document_df[document_df['cluster_label'] == 6]['opinion_text']):\n",
    "    print(i, t)\n",
    "    sentences.append(eval(t)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "693ae29f-6333-4c3f-a974-b546f185d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7708 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'삼성전자의 새로운 먹거리로 보였던 무선 이어폰이 애플이라는 큰 벽과 중국 기업의 저가 공세를 막지 못하면서 어려움을 겪고 있는 가운데, 삼성전자는 올해 무선 이어폰 신제품 출시는 없을 것으로 전망하고 업데이트로 대응 업계에서는 올해 무선 이어폰 신제품 출시는 없을 것으로 전망하고 있다.     '"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = make_summarization(sentences)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "472b1863-6348-4585-9a15-ec7f22adc4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_topic(document_df, topic_num):\n",
    "    sentences = []\n",
    "    for i,t in enumerate(document_df[document_df['cluster_label'] == topic_num]['opinion_text']):\n",
    "        sentences.append(eval(t)[1])\n",
    "    result = make_summarization(sentences)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d443fb0e-bea4-47a8-840b-66ec68e27822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7528 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'더 풍부하고 섬세한 사운드, 매끄러운 연결성, 향상된 배터리 수명을 제공하는 LE 오디오 기술은 보다 풍부하고 섬세한 사운드, 섬세한 사운드, 매끄러운 연결성, 향상된 배터리 수명을 제공하는 것이 특징이라고 회사는 설명했다.         '"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = summarize_topic(document_df, 0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5c4be610-3725-4f59-9840-a8b6aacc9c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8699 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'삼성전자는 갤럭시 스마트폰 동영상 촬영 시 360도 사운드 녹음이 가능하도록 갤럭시 버즈 2 프로와 갤럭시 Z 플립4 폴드4의 소프트웨어 업데이트를 시행하여 사용자가 직접 듣는 그대로의 생생한 사운드를 녹음할 수 있다고 밝혔다.  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = summarize_topic(document_df, 1)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eb06f49f-b75d-4ec5-9a65-e3ed859e5471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3841 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'삼성전자는 다음 워치5와 워치 4 시리즈에 카메라 줌 인, 줌 아웃 기능을 추가한다고 밝히며 다음 달 진행되는 갤럭시 언팩에서 새로운 갤럭시 스마트폰과 관련된 더 많은 내용을 소개할 것 이라고 말했다  \\n 삼성전자는 다음 달 갤럭시 워치5와 워치 4 시리즈에 카메라 줌 인, 줌 아웃 기능을 추가한다고 전했다.'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = summarize_topic(document_df, 2)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6e592a6d-cd9b-48f7-8ba6-436bc1474c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5630 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'스마트폰을 먼 거리에 세워두고 단체 사진이나 단독 셀카를 찍을 때 카메라가 있는 곳까지 돌아갈 필요 없이 손목에서 바로 손쉽게 화면 배율 조정을 할 수 있게 되어 손목에서 바로 손쉽게 화면 배율 조정을 할 수 있게 되었으며,  \\n 스마트폰을 먼 거리에 세워두고 단체 사진이나 단독 셀카를 찍을 때 카메라가 있는 곳까지 돌아갈 필요 없이 손목에서 바로 손쉽게 화면 배율 조정이 가능해진다.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = summarize_topic(document_df, 3)\n",
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5cede138-f79c-49bf-9e3e-bf0c839527e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1447 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'360 오디오 레코딩은 차세대 블 루투스 오디오 기술 표 준인 LE 오디오가 적용됐다.  련련련련련련련련련련련련련련련련련련은 차세대 블루투스 오디오 기술 표 준인 LE 오디오를 적용했다.'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4 = summarize_topic(document_df, 4)\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5a6570af-f33e-4aa5-a71c-0b17dc665834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9359 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'전문 장비 없이도 누구나  언제 어디서든 고품질의 실감 나는 오디오를 동영상에 담을 수 있다는 게 삼성전자의 설명으로 사용자는 시계 화면을 손가락으로 늘리거나 줄이는 핀치 동작이나, 시계의 베젤을 돌려 갤럭시 스마트폰의 카메라 줌을 원격으로 제어할 수 있게 되었으며 사용자는 시계 화면을 손가락으로 늘 리거나 줄이는 핀치 동작이나, 시계의 베젤을 돌려 갤럭시 스마트폰의 카메라 줌을 원격으로 제어할 수 있게 되었다.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result5 = summarize_topic(document_df, 5)\n",
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2108c17-fd45-4833-9358-f93250d87fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
